{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from os.path import abspath\n",
    "from os.path import dirname as up\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "# Insert path to pybf library to system path\n",
    "print(up(up(up(abspath(\"__file__\")))))\n",
    "path_to_lib = up(up(up(abspath(\"__file__\"))))\n",
    "print(path_to_lib)\n",
    "sys.path.insert(0, path_to_lib)\n",
    "\n",
    "#Import libraries and functions\n",
    "from pybf.pybf.io_interfaces import DataLoader\n",
    "from pybf.pybf.signal_processing import demodulate_decimate\n",
    "from pybf.pybf.signal_processing import interpolate_modulate\n",
    "from pybf.pybf.signal_processing import filter_band_pass\n",
    "from pybf.scripts.beamformer_cartesian_realtime import BFCartesianRealTime\n",
    "from pybf.pybf.transducer import Transducer\n",
    "from pybf.pybf.image_settings import ImageSettings\n",
    "from pybf.pybf.visualization import plot_image\n",
    "from pybf.scripts.beamformer_cartesian import beamformer_cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beamform and plot the original image\n",
    "\n",
    "dataset_path = \"../datasets/archive/archive_to_download/database/experiments/resolution_distorsion/rf_dataset.hdf5\"\n",
    "\n",
    "data_loader_obj = DataLoader(dataset_path)\n",
    "\n",
    "### Specify Image settings and create corresponding object ###\n",
    "\n",
    "img_res = [400, 600]\n",
    "image_x_range = [-0.019, 0.019]\n",
    "image_z_range = [0.005, 0.05]\n",
    "\n",
    "db_range = 50\n",
    "\n",
    "LATERAL_PIXEL_DENSITY_DEFAULT = 5\n",
    "\n",
    "img_config = ImageSettings(image_x_range[0],\n",
    "                           image_x_range[1],\n",
    "                           image_z_range[0],\n",
    "                           image_z_range[1],\n",
    "                           LATERAL_PIXEL_DENSITY_DEFAULT,\n",
    "                           data_loader_obj.transducer)\n",
    "\n",
    "### Specify preprocessing parameters for RF data ###\n",
    "\n",
    "decimation_factor = 1\n",
    "interpolation_factor = 10\n",
    "\n",
    "### Specify TX strategy and Apodization parameters ###\n",
    "\n",
    "start_time = 0\n",
    "correction_time_shift = 0\n",
    "\n",
    "alpha_fov_apod = 40\n",
    "\n",
    "### Specify Sampling Frequency ###\n",
    "\n",
    "SAMPLING_FREQ = 20.832 * (10 ** 6)\n",
    "\n",
    "filters_params = [1 * 10 **6, 8 * 10 **6, 0.5 * 10 **6]\n",
    "\n",
    "bf = BFCartesianRealTime(data_loader_obj.f_sampling,\n",
    "                         data_loader_obj.tx_strategy,\n",
    "                         data_loader_obj.transducer,\n",
    "                         decimation_factor,\n",
    "                         interpolation_factor,\n",
    "                         img_res,\n",
    "                         img_config,\n",
    "                         start_time=start_time,\n",
    "                         correction_time_shift=correction_time_shift,\n",
    "                         alpha_fov_apod=alpha_fov_apod,\n",
    "                         bp_filter_params=filters_params,\n",
    "                         envelope_detector='hilbert',\n",
    "                         picmus_dataset=True)\n",
    "\n",
    "rf_data_shape = (data_loader_obj.num_of_acq_per_frame,) + data_loader_obj.get_rf_data(0, 0).shape\n",
    "print('RF data shape: ', rf_data_shape)\n",
    "\n",
    "rf_data = np.zeros(rf_data_shape)\n",
    "for i in range(rf_data.shape[0]):\n",
    "    rf_data[i, :, :] = data_loader_obj.get_rf_data(0, i)\n",
    "\n",
    "# Beamforming\n",
    "img_data = bf.beamform(rf_data, numba_active=True)\n",
    "\n",
    "_ = plot_image(np.abs(img_data), \n",
    "               scatters_coords_xz=None,\n",
    "               elements_coords_xz=None,\n",
    "               framework='plotly',\n",
    "               title='Original Image (PW_75)',\n",
    "               image_x_range=image_x_range,\n",
    "               image_z_range=image_z_range,\n",
    "               db_range=db_range,\n",
    "               colorscale='Greys',\n",
    "               save_fig=True, \n",
    "               show=True,\n",
    "               path_to_save='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_rf_data(path_to_dataset):\n",
    "    \n",
    "    # Read file\n",
    "    data_loader_obj = DataLoader(path_to_dataset)\n",
    "    \n",
    "    rf_data_shape = (data_loader_obj.num_of_acq_per_frame,) + data_loader_obj.get_rf_data(0, 0).shape\n",
    "    print('RF data shape: ', rf_data_shape)\n",
    "\n",
    "    rf_data = np.zeros(rf_data_shape)\n",
    "    for i in range(rf_data.shape[0]):\n",
    "        rf_data[i, :, :] = data_loader_obj.get_rf_data(0, i)\n",
    "        \n",
    "    return rf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_original_data = get_original_rf_data(\"../datasets/archive/archive_to_download/database/experiments/contrast_speckle/rf_dataset.hdf5\")\n",
    "\n",
    "print(rf_original_data[0][1][223].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(rf_original_data[:][:]))\n",
    "\n",
    "print(np.min(rf_original_data[:][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass all the values of the dataset through the function and quantize them into integers between 0 and 4095\n",
    "\n",
    "rf_original_data = get_original_rf_data(\"../datasets/archive/archive_to_download/database/experiments/resolution_distorsion/rf_dataset.hdf5\")\n",
    "\n",
    "# Adjust range of original data to positive values\n",
    "rf_range_data = rf_original_data + 1\n",
    "print(rf_range_data.shape)\n",
    "\n",
    "bits_ADC = 10\n",
    "full_range = 2\n",
    "\n",
    "# Multiply all values with the following\n",
    "mult_with = ((2**bits_ADC)-1)/full_range\n",
    "\n",
    "mult_data = rf_range_data*mult_with\n",
    "print(mult_data.shape)\n",
    "flatten_mult_data = mult_data.flatten()\n",
    "print(flatten_mult_data.shape)\n",
    "\n",
    "# Convert to integers\n",
    "int_converted_data = np.zeros(rf_original_data.shape, dtype='int32')\n",
    "flatten_conv_data = int_converted_data.flatten()\n",
    "print(flatten_conv_data.shape)\n",
    "\n",
    "i = 0\n",
    "for sample in flatten_mult_data:\n",
    "    flatten_conv_data[i] = int(np.round(sample))\n",
    "    i = i+1\n",
    "    \n",
    "int_converted_data = flatten_conv_data.reshape(rf_original_data.shape)\n",
    "print(int_converted_data.shape)\n",
    "    \n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test analogue values with their integer conversion outputs\n",
    "print(rf_range_data[0][2][2])\n",
    "print(int_converted_data[0][2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the integer output values to a file\n",
    "with open('./BL_Coding/contrast_speckle/int_converted_values.npy', 'wb') as f:\n",
    "    np.save(f, int_converted_data)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load integer conversion output values from file\n",
    "import numpy as np\n",
    "with open('./BL_Coding/contrast_speckle/int_converted_values.npy', 'rb') as f:\n",
    "    int_out_values = np.load(f)\n",
    "f.close()\n",
    "print(int_out_values.shape)\n",
    "#print(int_converted_data[2][2][3])\n",
    "print(int_out_values[2][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot signals before and after conversion to make sure they look similar\n",
    "# Plot traces from a specific acquisition and channel\n",
    "from pybf.pybf.visualization import plot_trace\n",
    "\n",
    "# Original Traces\n",
    "path_to_save_original = \"./Original_Traces\"\n",
    "_ = plot_trace(rf_original_data, channel = 1, framework='plotly', save_fig=False, show=True, path_to_save=path_to_save_original)\n",
    "\n",
    "# ADC output Traces\n",
    "path_to_save_int = \"./Int_Conversion_Output_Traces\"\n",
    "_ = plot_trace(int_out_values, channel = 1, framework='plotly', save_fig=False, show=True, path_to_save=path_to_save_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integers to BL encoding values\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "# CREATE CLASS WITH MULTIPLE ARRAYS\n",
    "# ARRAY TO STORE PRE-FIXES\n",
    "# ARRAY TO STORE SUFFIXES\n",
    "# ARRAY TO STORE CONCATENATED VERSIONS\n",
    "# ARRAY TO STORE LENGTH OF PRE-FIX\n",
    "# ARRAY TO STORE LENGTH OF SUFFIX\n",
    "\n",
    "class BL_encoder():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 factor_S = 1):\n",
    "        \n",
    "        self._factor_S = factor_S\n",
    "        \n",
    "    def convert_to_int(self, path_to_dataset, path_to_save, bits_ADC, full_range):\n",
    "        \n",
    "        # Pass all the values of the dataset through the function and quantize them into integers between 0 and 4095\n",
    "        # Read file\n",
    "        data_loader_obj = DataLoader(path_to_dataset)\n",
    "\n",
    "        rf_data_shape = (data_loader_obj.num_of_acq_per_frame,) + data_loader_obj.get_rf_data(0, 0).shape\n",
    "        print('RF data shape: ', rf_data_shape)\n",
    "\n",
    "        rf_data = np.zeros(rf_data_shape)\n",
    "        for i in range(rf_data.shape[0]):\n",
    "            rf_data[i, :, :] = data_loader_obj.get_rf_data(0, i)\n",
    "            \n",
    "        rf_original_data = rf_data\n",
    "        print(\"RF Original Data shape: {}\".format(rf_original_data.shape))\n",
    "        \n",
    "        # Adjust range of original data to positive values\n",
    "        rf_range_data = rf_original_data + 1\n",
    "\n",
    "        bits_ADC = bits_ADC\n",
    "        full_range = full_range\n",
    "\n",
    "        # Multiply all values with the following\n",
    "        mult_with = ((2**bits_ADC)-1)/full_range\n",
    "\n",
    "        mult_data = rf_range_data*mult_with\n",
    "        print(mult_data.shape)\n",
    "        flatten_mult_data = mult_data.flatten()\n",
    "        print(flatten_mult_data.shape)\n",
    "\n",
    "        # Convert to integers\n",
    "        int_converted_data = np.zeros(rf_original_data.shape, dtype='int32')\n",
    "        flatten_conv_data = int_converted_data.flatten()\n",
    "        print(flatten_conv_data.shape)\n",
    "\n",
    "        i = 0\n",
    "        for sample in flatten_mult_data:\n",
    "            flatten_conv_data[i] = int(np.round(sample))\n",
    "            i = i+1\n",
    "\n",
    "        int_converted_data = flatten_conv_data.reshape(rf_original_data.shape)\n",
    "        print(\"Converted data shape: {}\".format(int_converted_data.shape))\n",
    "\n",
    "        print(\"Done converting to integers.\")\n",
    "        \n",
    "        # Write the integer output values to a file\n",
    "        with open(path_to_save, 'wb') as f:\n",
    "            np.save(f, int_converted_data)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        # Load integer conversion output values from file\n",
    "        with open(path_to_save, 'rb') as f:\n",
    "            int_out_values = np.load(f)\n",
    "            \n",
    "        f.close()\n",
    "        print(\"Recovered ints data shape: {}\".format(int_out_values.shape))\n",
    "        \n",
    "        return int_converted_data\n",
    "\n",
    "        \n",
    "        \n",
    "    def encode_data(self, path_to_int_array):\n",
    "        \n",
    "        S = self._factor_S\n",
    "        \n",
    "        # Load integer samples\n",
    "        with open(path_to_int_array, 'rb') as f:\n",
    "            int_array = np.load(f)\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "        # Calculate M\n",
    "        M = np.ceil(np.log2((int_array+(2**S))/(2**S)))\n",
    "        M = M.astype('int32')\n",
    "        print(\"Calculated M.\")\n",
    "        \n",
    "        # Calculate K\n",
    "        y = (1 + np.sqrt(1 + 8*M))/2\n",
    "        K = np.ceil(y)-1\n",
    "        K = K.astype('int32')\n",
    "        print(\"Calculated K.\")\n",
    "        \n",
    "        # Calculate X\n",
    "        X = M - (K*(K-1)/2)\n",
    "        X = X.astype('int32')\n",
    "        print(\"Calculated X.\")\n",
    "        \n",
    "        # Calculate number of zeros in prefix\n",
    "        numb_zeros = K - (X-1)\n",
    "        flatten_numb_zeros = numb_zeros.flatten()\n",
    "\n",
    "        zeros = []\n",
    "        i = 0\n",
    "        for sample in flatten_numb_zeros:\n",
    "            zeros.append(format(0, '#0{}b'.format(sample+2)))\n",
    "            i = i+1\n",
    "            \n",
    "        print(\"Calculated number of zeros in prefix.\")\n",
    "            \n",
    "        # Calculate number of ones in prefix\n",
    "        numb_ones = X-1\n",
    "        max_val = (2**numb_ones)-1\n",
    "        flatten_numb_ones = numb_ones.flatten()\n",
    "        flatten_max_val = max_val.flatten()\n",
    "\n",
    "        ones = []\n",
    "        for k in range(flatten_numb_ones.shape[0]):\n",
    "            max_value = flatten_max_val[k]\n",
    "            ones.append(format(max_value, '#0{}b'.format(flatten_numb_ones[k]+2)))\n",
    "            \n",
    "        print(\"Calculated number of ones in prefix.\")\n",
    "        \n",
    "        # Calculate binary clusters\n",
    "        binary_cluster = []\n",
    "\n",
    "\n",
    "        for i in range(flatten_numb_zeros.shape[0]):\n",
    "            single_bl = '0b1'\n",
    "\n",
    "            if (flatten_numb_zeros[i] != 0):\n",
    "                for char in zeros[i][2:]:\n",
    "                    single_bl = single_bl + char\n",
    "            if (flatten_numb_ones[i] != 0):\n",
    "                for char in ones[i][2:]:\n",
    "                    single_bl = single_bl + char\n",
    "\n",
    "            binary_cluster.append(single_bl)\n",
    "            \n",
    "        print(\"Calculated binary clusters.\")\n",
    "            \n",
    "        # Calculate prefixes\n",
    "        prefix = []\n",
    "\n",
    "        for i in range(len(binary_cluster)):\n",
    "            single_pr = '0b'\n",
    "            stringlength = len(binary_cluster[i])\n",
    "            string_sliced = binary_cluster[i][stringlength::-1]\n",
    "\n",
    "            for char in string_sliced[:-2]:\n",
    "                # Reverse number\n",
    "                single_pr = single_pr + char\n",
    "\n",
    "            prefix.append(single_pr)\n",
    "            \n",
    "        print(\"Calculated prefixes.\")\n",
    "            \n",
    "        # Calculate suffixes and lengths of suffixes\n",
    "        suffix_dec = int_array - ((2**S)*(2**(M-1)-1)) - 1\n",
    "        suffix_dec = suffix_dec.astype('int32')\n",
    "        \n",
    "        suffix_length = M + (S-1)\n",
    "        suffix_length = suffix_length.astype('int32')\n",
    "        \n",
    "        suffix = []\n",
    "\n",
    "        flatten_suffix_dec = suffix_dec.flatten()\n",
    "        flatten_suffix_length = suffix_length.flatten()\n",
    "\n",
    "        for k in range(flatten_suffix_dec.shape[0]):\n",
    "\n",
    "            if (flatten_suffix_length[k] != 0):\n",
    "                suffix.append(format(flatten_suffix_dec[k], '#0{}b'.format(flatten_suffix_length[k]+2)))\n",
    "        \n",
    "        print(\"Calculated suffixes and lengths of suffixes.\")\n",
    "        \n",
    "        # Concatenate prefixes and suffixes to get the BL codes and their lengths\n",
    "        bl_codes = []\n",
    "        bl_codes_length = []\n",
    "\n",
    "        for i in range(len(suffix)):\n",
    "            single_bl_code = '0b'\n",
    "\n",
    "            for char in prefix[i][2:]:\n",
    "                single_bl_code = single_bl_code + char\n",
    "            if (flatten_suffix_length[i] != 0):\n",
    "                for char in suffix[i][2:]:\n",
    "                    single_bl_code = single_bl_code + char\n",
    "\n",
    "            bl_codes.append(single_bl_code)\n",
    "            bl_codes_length.append(len(single_bl_code[2:]))\n",
    "            \n",
    "        # Return lists of bl_codes and bl_codes_length\n",
    "        print(\"Shape of BL codes array: {}\".format(len(bl_codes)))\n",
    "        print(\"Shape of BL lengths array: {}\".format(len(bl_codes_length)))\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        return bl_codes, bl_codes_length\n",
    "    \n",
    "    \n",
    "    # Save codes and lengths in a file\n",
    "    def save_data(self, path_to_save, name_codes, bl_codes, name_lengths, bl_codes_length):\n",
    "\n",
    "        # Write the BL codes and lengths to a file\n",
    "        with open(path_to_save + name_codes + '.npy', 'w') as f:\n",
    "            json.dump(bl_codes, f)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        with open(path_to_save + name_lengths + '.npy', 'w') as f:\n",
    "            json.dump(bl_codes_length, f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "    # Load BL codes and lengths from files\n",
    "    def load_data(self, path_to_bl_codes_data, path_to_bl_lengths_data):\n",
    "        \n",
    "        with open(path_to_bl_codes_data, 'r') as f:\n",
    "            bl_codes = json.load(f)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        with open(path_to_bl_lengths_data, 'r') as f:\n",
    "            bl_codes_length = json.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        return bl_codes, bl_codes_length\n",
    "    \n",
    "    def compression_ratio(self, integer_array, bl_codes_length):\n",
    "        \n",
    "        # Calculate compression ratio\n",
    "\n",
    "        # Initial size\n",
    "        initial_number_bits = (integer_array.size)*12\n",
    "        print(\"Initial size: {} bits.\".format(initial_number_bits))\n",
    "\n",
    "        # Compressed number of bits\n",
    "        compressed_number_bits = np.sum(bl_codes_length, dtype='int')\n",
    "        print(\"Compressed size: {} bits\".format(compressed_number_bits))\n",
    "\n",
    "        # Compression ratio\n",
    "        compr_ratio = (compressed_number_bits/initial_number_bits)*100\n",
    "        print(\"The compressed data is {:.2f}% of the original data.\".format(compr_ratio))\n",
    "        \n",
    "        return compr_ratio\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the encoder\n",
    "encoder = BL_encoder()\n",
    "\n",
    "# Convert the dataset from floats to integers in the range of the ADC\n",
    "integer_array = encoder.convert_to_int(\"../datasets/archive/archive_to_download/database/experiments/contrast_speckle/rf_dataset.hdf5\", \"./BL_Coding/int_converted_values.npy\", 12, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data\n",
    "\n",
    "encoder = BL_encoder()\n",
    "bl_codes, bl_codes_length = encoder.encode_data(\"./BL_Coding/int_converted_values.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save BL codes and their lengths to a file\n",
    "encoder = BL_encoder()\n",
    "encoder.save_data(\"./BL_Coding/\", \"BL_Codes_Contrast_Speckle_RF\", bl_codes, \"BL_Lengths_Contrast_Speckle_RF\", bl_codes_length)\n",
    "\n",
    "# Load BL codes and their lengths from a file\n",
    "bl_codes_file, bl_codes_length_file = encoder.load_data(\"./BL_Coding/BL_Codes_Contrast_Speckle_RF.npy\", \"./BL_Coding/BL_Lengths_Contrast_Speckle_RF.npy\")\n",
    "\n",
    "print(len(bl_codes_file))\n",
    "print(len(bl_codes_length_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load integer conversion output values from file\n",
    "import numpy as np\n",
    "with open('./BL_Coding/int_converted_values.npy', 'rb') as f:\n",
    "    integer_array = np.load(f)\n",
    "f.close()\n",
    "print(integer_array.shape)\n",
    "#print(integer_array[2][2][3])\n",
    "print(integer_array[2][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate compression ratio\n",
    "\n",
    "# Initial size\n",
    "initial_number_bits = (integer_array.size)*12\n",
    "print(\"Initial size: {} bits.\".format(initial_number_bits))\n",
    "\n",
    "# Compressed number of bits\n",
    "compressed_number_bits = np.sum(bl_codes_length_file, dtype='int')\n",
    "print(\"Compressed size: {} bits\".format(compressed_number_bits))\n",
    "\n",
    "# Compression ratio\n",
    "compr_ratio = (compressed_number_bits/initial_number_bits)*100\n",
    "print(\"The compressed data is {}% of the original data.\".format(compr_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-korean",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compression = encoder.compression_ratio(integer_array, bl_codes_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode values and get the integers back\n",
    "\n",
    "class BL_decoder():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 factor_S = 1):\n",
    "        \n",
    "        self._factor_S = factor_S\n",
    "\n",
    "    \n",
    "    def decode_data(self, path_to_bl_codes_data):\n",
    "        \n",
    "        S = self._factor_S\n",
    "        \n",
    "        with open(path_to_bl_codes_data, 'r') as f:\n",
    "            bl_codes = json.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        print(\"Shape of BL codes: {}\".format(len(bl_codes)))\n",
    "    \n",
    "        decoded_integers = np.zeros((len(bl_codes),), dtype=np.int32)\n",
    "\n",
    "        for i in range(len(bl_codes)):\n",
    "\n",
    "            for bit in range(2, len(bl_codes[i])-1):\n",
    "\n",
    "                if (bl_codes[i][bit] == '0' and bl_codes[i][bit+1] == '1'):\n",
    "                    prefix_dec = bl_codes[i][2:bit+2]\n",
    "                    break\n",
    "\n",
    "            prefix_length = len(prefix_dec)\n",
    "\n",
    "            K = prefix_length - 1\n",
    "\n",
    "            T = 0\n",
    "\n",
    "            if (prefix_dec[0] == '1'):\n",
    "                T = 1\n",
    "                for k in range(len(prefix_dec)):\n",
    "                    if (prefix_dec[k] == '1' and prefix_dec[k+1] == '1'):\n",
    "                        T = T + 1\n",
    "                    elif (prefix_dec[k+1] == '0'):\n",
    "                        break\n",
    "                        \n",
    "            M = int(((K*(K-1))/2) + T + 1)\n",
    "\n",
    "            suffix_length = M + (S-1)\n",
    "\n",
    "            suffix = bl_codes[i][2+prefix_length:(2+prefix_length) + suffix_length]\n",
    "\n",
    "            suffix_dec = int(suffix,2)\n",
    "\n",
    "            Z = suffix_dec + ((2**S)*((2**(M-1))-1)) + 1\n",
    "\n",
    "            decoded_integers[i] = Z\n",
    "            \n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write(\"{} out of 31948800\".format(i))\n",
    "            \n",
    "            \n",
    "        reshaped_decoded_int = np.reshape(decoded_integers, (75,128,3328))  \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        \n",
    "        return reshaped_decoded_int\n",
    "    \n",
    "    \n",
    "    def save_decoded_int(self, name_file, reshaped_decoded_int):\n",
    "        \n",
    "        # Save decoded integers array into file\n",
    "        with open(name_file + '.npy', 'wb') as f:\n",
    "            np.save(f, reshaped_decoded_int)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    def load_decoded_int(self, name_file):\n",
    "        \n",
    "        # Read file with decoded integers\n",
    "        with open(name_file, 'rb') as f:\n",
    "            reshaped_decod_int_file = np.load(f)\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        return reshaped_decod_int_file\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_everything(type_data,dataset):\n",
    "    \n",
    "    if (type_data == 'RF'):\n",
    "        typed = 'rf'\n",
    "        \n",
    "    elif (type_data == 'IQ'):\n",
    "        typed = 'iq'\n",
    "\n",
    "    \n",
    "    if dataset == 0:\n",
    "        path = \"resolution_distorsion\"\n",
    "        path_to_dataset = \"../datasets/archive/archive_to_download/database/experiments/resolution_distorsion/\" + typed + \"_dataset.hdf5\"\n",
    "    elif dataset == 1:\n",
    "        path = \"contrast_speckle\"\n",
    "        path_to_dataset = \"../datasets/archive/archive_to_download/database/experiments/contrast_speckle/\" + typed + \"_dataset.hdf5\"\n",
    "\n",
    "        \n",
    "    # Beamform and plot the original image    \n",
    "    data_loader_obj = DataLoader(path_to_dataset)\n",
    "    \n",
    "    \n",
    "    ### Specify Image settings and create corresponding object ###\n",
    "\n",
    "    img_res = [400, 600]\n",
    "    image_x_range = [-0.019, 0.019]\n",
    "    image_z_range = [0.005, 0.05]\n",
    "\n",
    "    db_range = 50\n",
    "\n",
    "    LATERAL_PIXEL_DENSITY_DEFAULT = 5\n",
    "\n",
    "    img_config = ImageSettings(image_x_range[0],\n",
    "                               image_x_range[1],\n",
    "                               image_z_range[0],\n",
    "                               image_z_range[1],\n",
    "                               LATERAL_PIXEL_DENSITY_DEFAULT,\n",
    "                               data_loader_obj.transducer)\n",
    "\n",
    "    ### Specify preprocessing parameters for RF data ###\n",
    "\n",
    "    decimation_factor = 1\n",
    "    interpolation_factor = 10\n",
    "\n",
    "    ### Specify TX strategy and Apodization parameters ###\n",
    "\n",
    "    start_time = 0\n",
    "    correction_time_shift = 0\n",
    "\n",
    "    alpha_fov_apod = 40\n",
    "\n",
    "    ### Specify Sampling Frequency ###\n",
    "\n",
    "    SAMPLING_FREQ = 20.832 * (10 ** 6)\n",
    "\n",
    "    filters_params = [1 * 10 **6, 8 * 10 **6, 0.5 * 10 **6]\n",
    "\n",
    "    bf = BFCartesianRealTime(data_loader_obj.f_sampling,\n",
    "                             data_loader_obj.tx_strategy,\n",
    "                             data_loader_obj.transducer,\n",
    "                             decimation_factor,\n",
    "                             interpolation_factor,\n",
    "                             img_res,\n",
    "                             img_config,\n",
    "                             start_time=start_time,\n",
    "                             correction_time_shift=correction_time_shift,\n",
    "                             alpha_fov_apod=alpha_fov_apod,\n",
    "                             bp_filter_params=filters_params,\n",
    "                             envelope_detector='hilbert',\n",
    "                             picmus_dataset=True)\n",
    "\n",
    "    rf_data_shape = (data_loader_obj.num_of_acq_per_frame,) + data_loader_obj.get_rf_data(0, 0).shape\n",
    "    print(typed + ' data shape: ', rf_data_shape)\n",
    "\n",
    "    rf_data = np.zeros(rf_data_shape)\n",
    "    for i in range(rf_data.shape[0]):\n",
    "        rf_data[i, :, :] = data_loader_obj.get_rf_data(0, i)\n",
    "\n",
    "    # Beamforming\n",
    "    img_data = bf.beamform(rf_data, numba_active=True)\n",
    "\n",
    "    _ = plot_image(np.abs(img_data), \n",
    "                   scatters_coords_xz=None,\n",
    "                   elements_coords_xz=None,\n",
    "                   framework='plotly',\n",
    "                   title='Original Image (PW_75)',\n",
    "                   image_x_range=image_x_range,\n",
    "                   image_z_range=image_z_range,\n",
    "                   db_range=db_range,\n",
    "                   colorscale='Greys',\n",
    "                   save_fig=True, \n",
    "                   show=True,\n",
    "                   path_to_save='.')\n",
    "    \n",
    "    # Declare the encoder\n",
    "    encoder = BL_encoder()\n",
    "\n",
    "    # Convert the dataset from floats to integers in the range of the ADC\n",
    "    integer_array = encoder.convert_to_int(path_to_dataset, \"./BL_Coding/\" + path + \"/int_converted_values.npy\", 12, 2)\n",
    "    \n",
    "    # Encode data\n",
    "    bl_codes, bl_codes_length = encoder.encode_data(\"./BL_Coding/\" + path + \"/int_converted_values.npy\")\n",
    "    \n",
    "    # Save BL codes and their lengths to a file\n",
    "    encoder = BL_encoder()\n",
    "    encoder.save_data(\"./BL_Coding/\", path + \"/BL_Codes_\" + path, bl_codes, path + \"/BL_Lengths_\" + path, bl_codes_length)\n",
    "\n",
    "    # Load BL codes and their lengths from a file\n",
    "    bl_codes_file, bl_codes_length_file = encoder.load_data(\"./BL_Coding/\" + path + \"/BL_Codes_\" + path + \".npy\", \"./BL_Coding/\" + path + \"/BL_Lengths_\" + path + \".npy\")\n",
    "        \n",
    "    # Calculate compression ratio\n",
    "    compression = encoder.compression_ratio(integer_array, bl_codes_length)\n",
    "    \n",
    "    # Reconstruct original analogue values from integers and beamform to get the reconstructed image\n",
    "    decoder = BL_decoder()\n",
    "    decoded_integers = decoder.decode_data(\"./BL_Coding/\" + path + \"/BL_Codes_\" + path + \".npy\")\n",
    "    \n",
    "    # Beamform and plot the compressed image\n",
    "    # Beamforming\n",
    "    img_data = bf.beamform(decoded_integers, numba_active=True)\n",
    "\n",
    "    _ = plot_image(np.abs(img_data), \n",
    "                   scatters_coords_xz=None,\n",
    "                   elements_coords_xz=None,\n",
    "                   framework='plotly',\n",
    "                   title=\"BL_Coding_\" + path,\n",
    "                   image_x_range=image_x_range,\n",
    "                   image_z_range=image_z_range,\n",
    "                   db_range=db_range,\n",
    "                   colorscale='Greys',\n",
    "                   save_fig=True, \n",
    "                   show=True,\n",
    "                   path_to_save='./BL_Coding/' + path)    \n",
    "    \n",
    "    # Prepare dataset to extract metrics of resolution and contrast\n",
    "\n",
    "    # Read info from file\n",
    "    f_d = h5py.File(\"../datasets/archive/archive_to_download/database/experiments/\" + path + \"/\" + path + \"_expe_dataset_\" + typed + \".hdf5\", \"r\")\n",
    "\n",
    "    attributes = f_d.attrs\n",
    "\n",
    "    US = f_d['US']\n",
    "    attributes = US.attrs\n",
    "\n",
    "    US_DATASET0000 = US['US_DATASET0000']\n",
    "    attributes = US_DATASET0000.attrs\n",
    "\n",
    "    type_s = attributes.__getitem__('type')\n",
    "\n",
    "    attributes = US_DATASET0000.attrs\n",
    "\n",
    "    keys_1 = list(f_d.keys());\n",
    "\n",
    "    US = f_d['US']\n",
    "\n",
    "    US_DATASET0000 = US['US_DATASET0000']\n",
    "\n",
    "    data = US_DATASET0000['data']\n",
    "\n",
    "    imag_n = data['imag']\n",
    "\n",
    "    real_n = data['real'][()]\n",
    "\n",
    "    PRF = US_DATASET0000['PRF']\n",
    "\n",
    "    angles = US_DATASET0000['angles']\n",
    "\n",
    "    initial_time = US_DATASET0000['initial_time']\n",
    "\n",
    "    modulation_frequency = US_DATASET0000['modulation_frequency']\n",
    "\n",
    "    probe_geometry = US_DATASET0000['probe_geometry']\n",
    "\n",
    "    sampling_frequency = US_DATASET0000['sampling_frequency']\n",
    "\n",
    "    sound_speed = US_DATASET0000['sound_speed']\n",
    "\n",
    "    # Create dataset suitable for calculating metrics\n",
    "\n",
    "    imag_np = np.zeros((75, 128, 3328))\n",
    "\n",
    "    # Creation of dataset\n",
    "\n",
    "    out_filename = './BL_Coding/bl_compressed_dataset.hdf5'\n",
    "    comp_file = h5py.File(out_filename,'w')\n",
    "    comp_file.close()\n",
    "    comp_file = h5py.File(out_filename,'a')\n",
    "\n",
    "    # Complete the structure\n",
    "\n",
    "    comp_file.attrs.create('version', [b'v.0.0.40'], dtype='|S9')\n",
    "\n",
    "    US_path = 'US'\n",
    "    US_group = comp_file.require_group(US_path)\n",
    "\n",
    "    US_dataset_group = US_group.require_group('US_DATASET0000')\n",
    "\n",
    "    US_dataset_group.attrs.create('type', [b\"US\"], dtype='|S2')\n",
    "    US_dataset_group.attrs.create('subtype', [b\"CPW\"], dtype='|S3')\n",
    "    US_dataset_group.attrs.create('signal_format', [b\"RF\"], dtype='|S2')\n",
    "    US_dataset_group.attrs.create('name', [b\"CIRS 040GSE Wires\"], dtype='|S18')\n",
    "    US_dataset_group.attrs.create('version', [b\"v1.96\"], dtype='|S6')\n",
    "    US_dataset_group.attrs.create('creation_date', [b\"2016/03/9 17:25:22.38\"], dtype='|S22')\n",
    "\n",
    "    # angles\n",
    "    US_dataset_group.create_dataset( 'angles', data=angles)\n",
    "\n",
    "    # PRF\n",
    "    US_dataset_group.create_dataset( 'PRF', data=PRF)\n",
    "\n",
    "    # initial_time\n",
    "    US_dataset_group.create_dataset( 'initial_time', data=initial_time)\n",
    "\n",
    "    # modulation frequency\n",
    "    US_dataset_group.create_dataset( 'modulation_frequency', data=modulation_frequency)\n",
    "\n",
    "    # probe geometry\n",
    "    US_dataset_group.create_dataset( 'probe_geometry', data=probe_geometry)\n",
    "\n",
    "    # sampling frequency\n",
    "    US_dataset_group.create_dataset( 'sampling_frequency', data=sampling_frequency)\n",
    "\n",
    "    # sound speed\n",
    "    US_dataset_group.create_dataset( 'sound_speed', data=sound_speed)\n",
    "\n",
    "    # imag data\n",
    "    data_group = US_dataset_group.require_group('data')\n",
    "    data_group.create_dataset('imag', data=imag_np)\n",
    "\n",
    "    # real data\n",
    "    rf_range_data = decoded_integers/2047.5\n",
    "    rf_data = rf_range_data - 1\n",
    "    data_group.create_dataset('real', data=rf_data)\n",
    "\n",
    "    comp_file.close()\n",
    "    f_d.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = encoder.compression_ratio(integer_array, bl_codes_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data\n",
    "path = 'resolution_distorsion'\n",
    "bl_codes, bl_codes_length = encoder.encode_data(\"./BL_Coding/\" + path + \"/int_converted_values.npy\")\n",
    "\n",
    "# Save BL codes and their lengths to a file\n",
    "encoder = BL_encoder()\n",
    "encoder.save_data(\"./BL_Coding/\", path + \"/BL_Codes_\" + path, bl_codes, path + \"/BL_Lengths_\" + path, bl_codes_length)\n",
    "\n",
    "# Load BL codes and their lengths from a file\n",
    "bl_codes_file, bl_codes_length_file = encoder.load_data(\"./BL_Coding/\" + path + \"/BL_Codes_\" + path + \".npy\", \"./BL_Coding/\" + path + \"/BL_Lengths_\" + path + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-pressing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reconstruct original analogue values from integers and beamform to get the reconstructed image\n",
    "\n",
    "decoder = BL_decoder()\n",
    "\n",
    "decoded_integers = decoder.decode_data(\"./BL_Coding/resolution_distorsion/BL_Codes_resolution_distorsion.npy\")\n",
    "print(decoded_integers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save decoded integers\n",
    "decoder.save_decoded_int(\"./BL_Coding/resolution_distorsion/decoded_integers\", decoded_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load decoded integers\n",
    "decoded_integers_file = decoder.load_decoded_int(\"./BL_Coding/resolution_distorsion/decoded_integers.npy\")\n",
    "print(decoded_integers_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BL codes and their lengths from a file\n",
    "encoder = BL_encoder()\n",
    "path = \"resolution_distorsion\"\n",
    "bl_codes_file, bl_codes_length_file = encoder.load_data(\"./BL_Coding/\" + path + \"/BL_Codes_\" + path + \".npy\", \"./BL_Coding/\" + path + \"/BL_Lengths_\" + path + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-mining",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run function\n",
    "\n",
    "# 0 is resolution_distortion\n",
    "# 1 is contrast_speckle\n",
    "\n",
    "do_everything('RF',1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
